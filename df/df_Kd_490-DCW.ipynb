{
 "cells": [
  {
   "source": [
    "# Notebook to compute the Kd 490 anomaly "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load libraries\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import file with processed data in .h5 format and open it as a dataframe 'df'\n",
    "## NOTE: This data can be avoided if a dtaframe is already created ##\n",
    "with pd.HDFStore('df_Kd_490.h5','r') as input:\n",
    "    df_Kd_490=input.get('df_Kd_490')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   Kd_490  days  month site_name  week  year\n",
       "0     NaN     1      1       IES     0  2003\n",
       "1     NaN     1      1       MAR     0  2003\n",
       "2     NaN     1      1       LRC     0  2003\n",
       "3     NaN     1      1       ELP     0  2003\n",
       "4     NaN     1      1       ESS     0  2003"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Kd_490</th>\n      <th>days</th>\n      <th>month</th>\n      <th>site_name</th>\n      <th>week</th>\n      <th>year</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>NaN</td>\n      <td>1</td>\n      <td>1</td>\n      <td>IES</td>\n      <td>0</td>\n      <td>2003</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>NaN</td>\n      <td>1</td>\n      <td>1</td>\n      <td>MAR</td>\n      <td>0</td>\n      <td>2003</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>NaN</td>\n      <td>1</td>\n      <td>1</td>\n      <td>LRC</td>\n      <td>0</td>\n      <td>2003</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>NaN</td>\n      <td>1</td>\n      <td>1</td>\n      <td>ELP</td>\n      <td>0</td>\n      <td>2003</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>NaN</td>\n      <td>1</td>\n      <td>1</td>\n      <td>ESS</td>\n      <td>0</td>\n      <td>2003</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "source": [
    "df_Kd_490.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def arrange_df (df):\n",
    "    'This function reindex, sort_values, interpolate NaNÂ´s and append the average of the week and average of month'\n",
    "    df = df.reindex(columns=['site_name','year','month','week','days','Kd_490']) # Re-order by column starting by 'site_name'\n",
    "    df = df.sort_values(by=['site_name','year','month','week','days']) # Re-order in ascendent mode\n",
    "    df=df.interpolate() # interpolate missing values averaging the nearest values.\n",
    "    df['Kd_W'] = df.groupby(['site_name','year','month','week'])['Kd_490'].transform('mean') # add columns\n",
    "    df['Kd_M'] = df.groupby(['site_name','year','month'])['Kd_490'].transform('mean') \n",
    "    \n",
    "    # compute monthly and weekly climatology\n",
    "    df['Kd_Mclim'] = df.groupby(['site_name','month'])['Kd_490'].transform('mean')\n",
    "    df['Kd_Wclim'] = df.groupby(['site_name','week'])['Kd_490'].transform('mean')\n",
    "    \n",
    "    # here we computed the weekly anomaly\n",
    "    df['Kd_W_Anomaly'] = df['Kd_W'] - df ['Kd_Wclim']\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_Kd_490 = arrange_df(df_Kd_490)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Round values to 3 digits \n",
    "df_Kd_490['Kd_490'] = round(df_Kd_490['Kd_490'],3)\n",
    "df_Kd_490['Kd_M'] = round(df_Kd_490['Kd_M'],3)\n",
    "df_Kd_490['Kd_W'] = round(df_Kd_490['Kd_W'],3)\n",
    "df_Kd_490['Kd_Mclim'] = round(df_Kd_490['Kd_Mclim'],3)\n",
    "df_Kd_490['Kd_Wclim'] = round(df_Kd_490['Kd_Wclim'],3)\n",
    "df_Kd_490['Kd_W_Anomaly'] = round(df_Kd_490['Kd_W_Anomaly'],3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_Kd_490.to_csv('Kd_490.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python37464bitbaseconda2bfc37613f1f4f60853ed4e315607ebc",
   "display_name": "Python 3.7.4 64-bit ('base': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "metadata": {
   "interpreter": {
    "hash": "3bed7ae5c37a2f0124a3d1d7ebe9444ba8b4d4f68ec45ffe4ebc67430627124e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}